{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "# Folder structure\n",
    "\n",
    "# data/train/RETARGETTED    - RETARGETTED train samples\n",
    "# data/train/NATURAL        - naturaltrain samples\n",
    "# data/train/DIBR           - DIBR train samples\n",
    "# data/train/SCREENSHOTS    - SCREENSHOT train samples\n",
    "\n",
    "\n",
    "# data/test/RETARGETTED    - RETARGETTED test samples\n",
    "# data/test/NATURAL        - natural test samples\n",
    "# data/test/DIBR           - DIBR test samples\n",
    "# data/test/SCREENSHOTS    - SCREENSHOT test samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150 # Resolution of inputs\n",
    "train_data_dir = \"train\"           # Folder of train samples\n",
    "validation_data_dir = \"test\" # Folder of validation samples\n",
    "nb_train_samples =  23774              # Number of train samples\n",
    "nb_validation_samples =  9773           # Number of validation samples\n",
    "batch_size = 16                        # Batch size\n",
    "epochs = 100                # Maximum number of epochs\n",
    "dataset_path = os.getcwd() + '/dataset' # Place where dataset images are stored\n",
    "split_percent = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassX has 350 samples.\n",
      "X class folder splited!\n",
      "ClassFever has 350 samples.\n",
      "Fever class folder splited!\n",
      "ClassTwo has 352 samples.\n",
      "Two class folder splited!\n",
      "ClassOath has 350 samples.\n",
      "Oath class folder splited!\n",
      "ClassStand has 350 samples.\n",
      "Stand class folder splited!\n",
      "ClassU has 350 samples.\n",
      "U class folder splited!\n",
      "ClassSoldier has 350 samples.\n",
      "Soldier class folder splited!\n",
      "ClassSleep has 350 samples.\n",
      "Sleep class folder splited!\n",
      "ClassSunday has 350 samples.\n",
      "Sunday class folder splited!\n",
      "ClassA has 350 samples.\n",
      "A class folder splited!\n",
      "ClassEvening has 350 samples.\n",
      "Evening class folder splited!\n",
      "ClassCow has 352 samples.\n",
      "Cow class folder splited!\n",
      "ClassThumbs_up has 350 samples.\n",
      "Thumbs_up class folder splited!\n",
      "ClassElbow has 350 samples.\n",
      "Elbow class folder splited!\n",
      "ClassFive has 350 samples.\n",
      "Five class folder splited!\n",
      "ClassR has 350 samples.\n",
      "R class folder splited!\n",
      "ClassM has 350 samples.\n",
      "M class folder splited!\n",
      "ClassCough has 350 samples.\n",
      "Cough class folder splited!\n",
      "ClassClaw has 350 samples.\n",
      "Claw class folder splited!\n",
      "ClassWest has 350 samples.\n",
      "West class folder splited!\n",
      "ClassC has 352 samples.\n",
      "C class folder splited!\n",
      "ClassI has 350 samples.\n",
      "I class folder splited!\n",
      "ClassP has 350 samples.\n",
      "P class folder splited!\n",
      "ClassEye has 350 samples.\n",
      "Eye class folder splited!\n",
      "ClassHair has 350 samples.\n",
      "Hair class folder splited!\n",
      "ClassYou has 350 samples.\n",
      "You class folder splited!\n",
      "ClassWedding has 350 samples.\n",
      "Wedding class folder splited!\n",
      "ClassFaith has 350 samples.\n",
      "Faith class folder splited!\n",
      "ClassOwl has 350 samples.\n",
      "Owl class folder splited!\n",
      "ClassHand has 350 samples.\n",
      "Hand class folder splited!\n",
      "ClassSick has 350 samples.\n",
      "Sick class folder splited!\n",
      "ClassDoctor has 350 samples.\n",
      "Doctor class folder splited!\n",
      "ClassAdd has 350 samples.\n",
      "Add class folder splited!\n",
      "ClassT has 352 samples.\n",
      "T class folder splited!\n",
      "ClassG has 352 samples.\n",
      "G class folder splited!\n",
      "ClassL has 350 samples.\n",
      "L class folder splited!\n",
      "ClassFood has 350 samples.\n",
      "Food class folder splited!\n",
      "ClassK has 350 samples.\n",
      "K class folder splited!\n",
      "ClassWord has 350 samples.\n",
      "Word class folder splited!\n",
      "ClassBud has 350 samples.\n",
      "Bud class folder splited!\n",
      "ClassShirt has 350 samples.\n",
      "Shirt class folder splited!\n",
      "ClassWater has 350 samples.\n",
      "Water class folder splited!\n",
      "ClassGood has 350 samples.\n",
      "Good class folder splited!\n",
      "ClassMe has 352 samples.\n",
      "Me class folder splited!\n",
      "ClassBlind has 350 samples.\n"
     ]
    }
   ],
   "source": [
    "dataset_path\n",
    "\n",
    "number_of_classes = len(os.listdir(dataset_path))\n",
    "classes = list(os.listdir(dataset_path))\n",
    "\n",
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "os.makedirs(validation_data_dir, exist_ok=True)\n",
    "# every class has 350 samples\n",
    "for c in classes:\n",
    "    sample_dir = os.listdir(dataset_path + '/' + c)\n",
    "    number_sample = len(sample_dir)\n",
    "    \n",
    "    print('Class' + c + ' has ' + str(number_sample) + ' samples.')\n",
    "    \n",
    "    # create directories to move data\n",
    "    os.makedirs(train_data_dir + '/' + c, exist_ok = True)\n",
    "    os.makedirs(validation_data_dir + '/' + c, exist_ok = True)\n",
    "    \n",
    "    # move data based on split percentage to TEST\n",
    "    [shutil.copy(os.path.join(dataset_path, c, class_folder), os.path.join(train_data_dir, c, class_folder)) for class_folder in sample_dir[:int(split_percent * number_sample)]]\n",
    "    \n",
    "    [shutil.copy(os.path.join(dataset_path, c, class_folder), os.path.join(validation_data_dir, c, class_folder)) for class_folder in sample_dir[int(split_percent * number_sample):]]\n",
    "    \n",
    "    move_data(validation_data_dir)\n",
    "    print(c + ' class folder splited!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load INCEPTIONV3\n",
    "model=applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(img_width, img_height, 3))\n",
    "# Freeze first 15 layers\n",
    "for layer in model.layers[:45]:\n",
    "\tlayer.trainable = False\n",
    "for layer in model.layers[45:]:\n",
    "   layer.trainable = True\n",
    "\t\n",
    "# Attach additional layers\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(95, activation=\"softmax\")(x) # 4-way softmax classifier at the end\n",
    "\n",
    "model_final = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=1e-3, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# train data generator (data augmentation)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True,vertical_flip =True, fill_mode=\"nearest\", zoom_range=0.3, width_shift_range=0.3, height_shift_range=0.3,channel_shift_range=0.3)\n",
    "# test data generator (data augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True,vertical_flip =True, fill_mode=\"nearest\", zoom_range=0.3, width_shift_range=0.3, height_shift_range=0.3,channel_shift_range=0.3)\n",
    "\n",
    "# load from directory\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode=\"categorical\")\n",
    "# load from directory\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), class_mode=\"categorical\")\n",
    "\n",
    "# save models\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_weights_1.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# early stopping\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "# TRAINING\n",
    "history = model_final.fit_generator(train_generator, steps_per_epoch=1000, epochs=100, validation_data=validation_generator,validation_steps=500, callbacks=callbacks_list)\n",
    "\n",
    "model_final.save_weights(\"inception_main_test_1.h5\", overwrite = True)\n",
    "model_json = model_final.to_json()\n",
    "\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "#training_set = train_datagen.flow_from_directory('validation',\n",
    " #                                                target_size = (300,300),\n",
    "  #                                               batch_size = 8,\n",
    "   #                                              class_mode = 'categorical')\n",
    "\n",
    "#model.load_weights('inception_main.h5')\n",
    "\n",
    "#X,y = training_set.next()\n",
    "#result = model_final.predict_classes(X)\n",
    "#print(result)\n",
    "\n",
    "                  \n",
    "#list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for train\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig.savefig('model accuracy.jpg')\n",
    "plt.close(fig)\n",
    "#plt.show()\n",
    "\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
